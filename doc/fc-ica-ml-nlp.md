# LLM ì´ì „ì˜ AIë¥¼ ë§Œë‚˜ë‹¤
### ê³ ì „ì  ë¨¸ì‹ ëŸ¬ë‹ê³¼ ìì—°ì–´ ì²˜ë¦¬ ê¸°ìˆ ì˜ ì´í•´

---

## ğŸš€ ì˜¤í”„ë‹: "AIê°€ LLMë§Œì€ ì•„ë‹ˆë‹¤"

ì—¬ëŸ¬ë¶„ì´ ë§¤ì¼ ì‚¬ìš©í•˜ëŠ” ì„œë¹„ìŠ¤ë¥¼ ìƒê°í•´ ë³´ì„¸ìš”.

- ë„·í”Œë¦­ìŠ¤ê°€ ì˜í™”ë¥¼ ì¶”ì²œí•  ë•Œ
- ì€í–‰ì´ ì´ìƒ ê±°ë˜ë¥¼ íƒì§€í•  ë•Œ
- ì‡¼í•‘ëª°ì´ "ì´ ìƒí’ˆì„ êµ¬ë§¤í•œ ì‚¬ëŒë“¤ì´ í•¨ê»˜ ì‚° ìƒí’ˆ"ì„ ë³´ì—¬ì¤„ ë•Œ
- ìŠ¤íŒ¸ ë©”ì¼ì´ ìë™ìœ¼ë¡œ ê±¸ëŸ¬ì§ˆ ë•Œ

ì´ ëª¨ë“  ê¸°ëŠ¥ì˜ ë°‘ë°”íƒ•ì—ëŠ” ChatGPTê°€ ì—†ìŠµë‹ˆë‹¤.  
**ìˆ˜ì‹­ ë…„ ì—­ì‚¬ë¥¼ ê°€ì§„ ê³ ì „ì  ë¨¸ì‹ ëŸ¬ë‹ê³¼ ìì—°ì–´ ì²˜ë¦¬ ê¸°ìˆ **ì´ ì¡°ìš©íˆ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤.

```mermaid
mindmap
  root((AIì˜ ì„¸ê³„))
    ê³ ì „ì  ë¨¸ì‹ ëŸ¬ë‹
      íšŒê·€
      ë¶„ë¥˜
      êµ°ì§‘í™”
    ë”¥ëŸ¬ë‹
      CNN Â· RNN Â· Transformer
      LLM
    ê³ ì „ì  ìì—°ì–´ ì²˜ë¦¬
      í˜•íƒœì†Œ ë¶„ì„
      í‚¤ì›Œë“œ/ì—°ê´€ì–´ ë¶„ì„
      í‚¤ì›Œë“œ ë„¤íŠ¸ì›Œí¬ ë¶„ì„
      í† í”½ ë¶„ì„ LDA
      ë¬¸ì„œ ë¶„ë¥˜/êµ°ì§‘í™”
```

> ğŸ’¡ **í•µì‹¬ ë©”ì‹œì§€**: LLMì€ ê°•ë ¥í•˜ì§€ë§Œ ë¹„ìŒ‰ë‹ˆë‹¤. ê³ ì „ì  AI ê¸°ìˆ ì€ ë¹ ë¥´ê³ , ì €ë ´í•˜ê³ , ì„¤ëª… ê°€ëŠ¥í•©ë‹ˆë‹¤. ì¢‹ì€ AI ì„œë¹„ìŠ¤ ê¸°íšìëŠ” ë‘˜ì„ êµ¬ë¶„í•˜ê³  ì ì¬ì ì†Œì— í™œìš©í•©ë‹ˆë‹¤.

---

## Part 1. ê³ ì „ì  ë¨¸ì‹ ëŸ¬ë‹ í•µì‹¬ 3ê°€ì§€

### 1-1. íšŒê·€ (Regression) â€” "ì–¼ë§ˆì¼ê¹Œìš”?"

**í•œ ì¤„ ì •ì˜**: ì—°ì†ì ì¸ ìˆ«ìê°’ì„ ì˜ˆì¸¡í•˜ëŠ” ê¸°ìˆ 

**ë¹„ìœ **: ë¶€ë™ì‚° ì¤‘ê°œì¸ì´ "ì´ ì•„íŒŒíŠ¸ëŠ” í‰ìˆ˜, ì¸µìˆ˜, ìœ„ì¹˜ë¥¼ ë³´ë©´ ëŒ€ëµ Xì–µì¯¤ ë˜ê² êµ°ìš”" í•˜ëŠ” íŒë‹¨ì„ ìˆ˜í•™ìœ¼ë¡œ ë§Œë“  ê²ƒ

**ì‹¤ì œ ì„œë¹„ìŠ¤ ì ìš© ì‚¬ë¡€**

- ì¤‘ê³ ì°¨ í”Œë«í¼: ì—°ì‹Â·ì£¼í–‰ê±°ë¦¬Â·ì˜µì…˜ â†’ ì ì • ì‹œì„¸ ìë™ ì‚°ì¶œ
- ë‚ ì”¨ ì•±: ê³¼ê±° ê¸°ì˜¨ ë°ì´í„° â†’ ë‚´ì¼ ê¸°ì˜¨ ì˜ˆì¸¡
- ê´‘ê³  í”Œë«í¼: ìº í˜ì¸ ì˜ˆì‚°Â·ê¸°ê°„Â·íƒ€ê²ŸíŒ… â†’ ì˜ˆìƒ í´ë¦­ìˆ˜ ì˜ˆì¸¡
- ì „ììƒê±°ë˜: ê³¼ê±° ë§¤ì¶œ ë°ì´í„° â†’ ì¬ê³  ìˆ˜ìš” ì˜ˆì¸¡

**í•µì‹¬ ì›ë¦¬ (ë¹„ê°œë°œìë„ ì´í•´í•  ìˆ˜ ìˆëŠ” ìˆ˜ì¤€)**

```
ì‹¤ì œ ë°ì´í„°: ì•„íŒŒíŠ¸ ë©´ì (ã¡) vs ê°€ê²©(ë§Œì›)
  50ã¡ â†’ 30,000ë§Œì›
  70ã¡ â†’ 42,000ë§Œì›
  90ã¡ â†’ 54,000ë§Œì›

ëª¨ë¸ì´ ì°¾ì€ ê·œì¹™: ê°€ê²© â‰ˆ ë©´ì  Ã— 600ë§Œì›
â†’ 65ã¡ì§œë¦¬? â†’ ì•½ 39,000ë§Œì› ì˜ˆì¸¡!
```

**ê¸°íšìÂ·ë””ìì´ë„ˆê°€ ì•Œì•„ì•¼ í•  í¬ì¸íŠ¸**

- í•™ìŠµ ë°ì´í„°ì˜ í’ˆì§ˆì´ ì˜ˆì¸¡ ì •í™•ë„ë¥¼ ê²°ì •í•©ë‹ˆë‹¤
- ì˜ˆì¸¡ê°’ì—ëŠ” í•­ìƒ ì˜¤ì°¨ ë²”ìœ„ê°€ ì¡´ì¬í•©ë‹ˆë‹¤ (Â± í‘œì‹œ ì¤‘ìš”)
- ì´ìƒì¹˜(outlier) ë°ì´í„°ê°€ ê²°ê³¼ë¥¼ ì™œê³¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

---

### 1-2. ë¶„ë¥˜ (Classification) â€” "ì–´ëŠ ìª½ì¸ê°€ìš”?"

**í•œ ì¤„ ì •ì˜**: ë°ì´í„°ë¥¼ ë¯¸ë¦¬ ì •í•´ì§„ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ëŠ” ê¸°ìˆ 

**ë¹„ìœ **: ìš°ì²´êµ­ ë¶„ë¥˜ê¸°ê°€ ìš°í¸ë²ˆí˜¸ë¥¼ ë³´ê³  ì–´ëŠ ì§€ì—­ ë°•ìŠ¤ì— ë„£ì„ì§€ ê²°ì •í•˜ëŠ” ê²ƒ

**ì‹¤ì œ ì„œë¹„ìŠ¤ ì ìš© ì‚¬ë¡€**

- ì´ë©”ì¼: ìŠ¤íŒ¸(Spam) / ì •ìƒ(Ham) ë¶„ë¥˜
- ê¸ˆìœµ: ëŒ€ì¶œ ìŠ¹ì¸(Yes) / ê±°ì ˆ(No) íŒë‹¨
- ì˜ë£Œ: X-ray ì´ë¯¸ì§€ â†’ ì •ìƒ / ì´ìƒ ì§•í›„ ê°ì§€
- CS ì±—ë´‡: ê³ ê° ë¬¸ì˜ â†’ ë°°ì†¡/í™˜ë¶ˆ/ê²°ì œ/ê¸°íƒ€ ìë™ ë¶„ë¥˜
- SNS: ì—…ë¡œë“œ ì´ë¯¸ì§€ â†’ ìŒë€ë¬¼ ì—¬ë¶€ ìë™ í•„í„°ë§

**í•µì‹¬ ì›ë¦¬**

```
í•™ìŠµ ë‹¨ê³„:
  "ì´ ë©”ì¼(ê´‘ê³  ë¬¸êµ¬ í¬í•¨, ëª¨ë¥´ëŠ” ë°œì‹ ì¸)ì€ ìŠ¤íŒ¸ì´ì•¼" Ã— 10ë§Œ ê±´
  "ì´ ë©”ì¼(ë™ë£Œ ë°œì‹ , ì—…ë¬´ ë‚´ìš©)ì€ ì •ìƒì´ì•¼" Ã— 10ë§Œ ê±´
  â†’ ëª¨ë¸ì´ ìŠ¤íŒ¸ì˜ íŒ¨í„´ì„ í•™ìŠµ

ì˜ˆì¸¡ ë‹¨ê³„:
  ìƒˆë¡œìš´ ë©”ì¼ â†’ ëª¨ë¸ â†’ "ìŠ¤íŒ¸ì¼ í™•ë¥  94%" â†’ ìŠ¤íŒ¸í•¨ìœ¼ë¡œ!
```

**ì´ì§„ ë¶„ë¥˜ vs ë‹¤ì¤‘ ë¶„ë¥˜**

| êµ¬ë¶„ | ì˜ˆì‹œ | ì¶œë ¥ |
|------|------|------|
| ì´ì§„ ë¶„ë¥˜ | ìŠ¤íŒ¸ ì—¬ë¶€ | Yes / No |
| ë‹¤ì¤‘ ë¶„ë¥˜ | ìƒí’ˆ ì¹´í…Œê³ ë¦¬ | ì˜ë¥˜/ì‹í’ˆ/ì „ì/ê°€êµ¬/â€¦ |

**ê¸°íšìÂ·ë””ìì´ë„ˆê°€ ì•Œì•„ì•¼ í•  í¬ì¸íŠ¸**

- ë¶„ë¥˜ ê²°ê³¼ì—ëŠ” í™•ë¥ ê°’ì´ í•¨ê»˜ ë‚˜ì˜µë‹ˆë‹¤ (ì‹ ë¢°ë„ UI ì„¤ê³„ì— ì¤‘ìš”)
- ì˜¤ë¶„ë¥˜ ë¹„ìš©ì„ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤: ìŠ¤íŒ¸ì„ ì •ìƒìœ¼ë¡œ ë¶„ë¥˜ vs ì •ìƒì„ ìŠ¤íŒ¸ìœ¼ë¡œ ë¶„ë¥˜, ì–´ëŠ ìª½ì´ ë” ë‚˜ìœê°€?
- í•™ìŠµ ë°ì´í„°ì˜ í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤ (ì‚¬ê¸° ê±°ë˜ëŠ” ì „ì²´ì˜ 0.1%ë¿)

---

### 1-3. êµ°ì§‘í™” (Clustering) â€” "ë¹„ìŠ·í•œ ê²ƒë¼ë¦¬ ë¬¶ì–´ìš”"

**í•œ ì¤„ ì •ì˜**: ì •ë‹µ ì—†ì´ ë°ì´í„°ë¥¼ ìŠ¤ìŠ¤ë¡œ ë¹„ìŠ·í•œ ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê¸°ìˆ   
*(ë¶„ë¥˜ì™€ì˜ ê²°ì •ì  ì°¨ì´: êµ°ì§‘í™”ëŠ” ì •ë‹µ ë ˆì´ë¸”ì´ ì—†ëŠ” ë¹„ì§€ë„í•™ìŠµ)*

**ë¹„ìœ **: ìƒˆ í•™ê¸° ì²«ë‚  í•™ìƒë“¤ì„ ì•„ë¬´ëŸ° ê¸°ì¤€ ì—†ì´ ì„ì–´ë†“ê³ , AIê°€ "ì·¨ë¯¸, ì„±ì , ê±°ì£¼ì§€ê°€ ë¹„ìŠ·í•œ í•™ìƒë“¤ë¼ë¦¬ ìŠ¤ìŠ¤ë¡œ ë­‰ì³ë¼"ê³  í•˜ëŠ” ê²ƒ

**ì‹¤ì œ ì„œë¹„ìŠ¤ ì ìš© ì‚¬ë¡€**

- ë§ˆì¼€íŒ…: ê³ ê°ì„ VIP/ì¼ë°˜/ì´íƒˆìœ„í—˜ ë“± ì„¸ê·¸ë¨¼íŠ¸ë¡œ ìë™ ë¶„ë¥˜
- ì»¤ë¨¸ìŠ¤: êµ¬ë§¤ íŒ¨í„´ì´ ìœ ì‚¬í•œ ê³ ê° ê·¸ë£¹ ë°œê²¬ â†’ ê°œì¸í™” ì¶”ì²œ
- ì½˜í…ì¸ : ë¹„ìŠ·í•œ ê¸°ì‚¬ë“¤ì„ ìë™ìœ¼ë¡œ í† í”½ë³„ë¡œ ë¬¶ê¸°
- UX ë¦¬ì„œì¹˜: ì‚¬ìš©ì í–‰ë™ ë¡œê·¸ë¥¼ ë¶„ì„í•´ ì‚¬ìš©ì ìœ í˜• ë°œê²¬

**í•µì‹¬ ì›ë¦¬ (K-Means)**

```mermaid
flowchart TD
    A["1ë‹¨ê³„: ê·¸ë£¹ ìˆ˜ ì§€ì • (K=3)"]
    B["2ë‹¨ê³„: ì„ì˜ë¡œ 3ê°œ ì¤‘ì‹¬ì  ë°°ì¹˜"]
    C["3ë‹¨ê³„: ê° ë°ì´í„°ë¥¼ ê°€ì¥ ê°€ê¹Œìš´ ì¤‘ì‹¬ì  ê·¸ë£¹ì— ë°°ì •"]
    D["4ë‹¨ê³„: ê·¸ë£¹ ë‚´ í‰ê· ìœ¼ë¡œ ì¤‘ì‹¬ì  ì´ë™"]
    E{ë³€í™” ì—†ìŒ?}
    F["ê²°ê³¼: 3ê°œì˜ ê³ ê° êµ°ì§‘ ì™„ì„±!"]
    A --> B --> C --> D --> E
    E -- ì•„ë‹ˆì˜¤ --> C
    E -- ì˜ˆ --> F
```

**ê¸°íšìÂ·ë””ìì´ë„ˆê°€ ì•Œì•„ì•¼ í•  í¬ì¸íŠ¸**

- ê·¸ë£¹ ìˆ˜(K)ëŠ” ì‚¬ëŒì´ ê²°ì •í•´ì•¼ í•©ë‹ˆë‹¤ (ë¹„ì¦ˆë‹ˆìŠ¤ ë§¥ë½ í•„ìš”)
- êµ°ì§‘ì˜ ì´ë¦„/ì˜ë¯¸ í•´ì„ì€ ë„ë©”ì¸ ì „ë¬¸ê°€ê°€ í•´ì•¼ í•©ë‹ˆë‹¤
- ê²°ê³¼ëŠ” í™•ë¥ ì´ ì•„ë‹ˆë¼ ê·¸ë£¹ ë²ˆí˜¸ë¡œ ë‚˜ì˜µë‹ˆë‹¤

---

## Part 2. ê³ ì „ì  ìì—°ì–´ ì²˜ë¦¬(NLP) ê¸°ìˆ 

> ì´ ì˜ì—­ì€ **í•œêµ­ì–´ ì„œë¹„ìŠ¤**ë¥¼ ê¸°íší•˜ëŠ” ì—¬ëŸ¬ë¶„ì—ê²Œ íŠ¹íˆ ì¤‘ìš”í•©ë‹ˆë‹¤.  
> ë¦¬ë·° ë¶„ì„, ê²€ìƒ‰ ìë™ì™„ì„±, íŠ¸ë Œë“œ íŒŒì•… ë“± í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ì„œë¹„ìŠ¤ì˜ í•µì‹¬ì…ë‹ˆë‹¤.

---

### 2-1. í˜•íƒœì†Œ ë¶„ì„ â€” ëª¨ë“  í…ìŠ¤íŠ¸ AIì˜ ì‹œì‘ì 

**í•œ ì¤„ ì •ì˜**: ë¬¸ì¥ì„ ì˜ë¯¸ ìˆëŠ” ìµœì†Œ ë‹¨ìœ„(í˜•íƒœì†Œ)ë¡œ ìª¼ê°œëŠ” ê¸°ìˆ 

**ì™œ í•„ìš”í•œê°€?** ì»´í“¨í„°ëŠ” "ë‚˜ëŠ” í•™êµì— ê°”ë‹¤"ë¥¼ ê·¸ëƒ¥ ë¬¸ìì—´ë¡œ ë´…ë‹ˆë‹¤.  
í˜•íƒœì†Œ ë¶„ì„ì„ í•˜ë©´ `ë‚˜(ëŒ€ëª…ì‚¬)`, `ëŠ”(ì¡°ì‚¬)`, `í•™êµ(ëª…ì‚¬)`, `ì—(ì¡°ì‚¬)`, `ê°€(ë™ì‚¬)`, `ì•˜ë‹¤(ì–´ë¯¸)`ë¡œ ë¶„ë¦¬ë©ë‹ˆë‹¤.

**í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ê¸° ì¢…ë¥˜**

| ë„êµ¬ | íŠ¹ì§• | ì£¼ìš” ì‚¬ìš©ì²˜ |
|------|------|------------|
| KoNLPy (Okt, Kkma ë“±) | Python, ì˜¤í”ˆì†ŒìŠ¤ | ìŠ¤íƒ€íŠ¸ì—…, ë¶„ì„ í”„ë¡œì íŠ¸ |
| ì€ì „í•œë‹¢ (mecab-ko) | ë¹ ë¥¸ ì†ë„ | ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ |
| Kiwi | ìµœì‹ , ì •í™•ë„ ë†’ìŒ | í˜„ì—… ì¶”ì²œ |
| ë„¤ì´ë²„ clova | API ë°©ì‹, ë†’ì€ ì •í™•ë„ | ìƒìš© ì„œë¹„ìŠ¤ |

**í˜•íƒœì†Œ ë¶„ì„ ê²°ê³¼ ì˜ˆì‹œ**

```
ì…ë ¥: "ì˜¤ëŠ˜ ë°°ë‹¬ìŒì‹ì´ ë„ˆë¬´ ë§›ìˆì—ˆì–´ìš”! ë˜ ì‹œí‚¬ê²Œìš”"

ì¶œë ¥:
  ì˜¤ëŠ˜    â†’ ëª…ì‚¬
  ë°°ë‹¬    â†’ ëª…ì‚¬
  ìŒì‹    â†’ ëª…ì‚¬  â† í‚¤ì›Œë“œ ì¶”ì¶œì— í™œìš©
  ì´      â†’ ì¡°ì‚¬  â† ë¶„ì„ì—ì„œ ì œì™¸(ë¶ˆìš©ì–´)
  ë„ˆë¬´    â†’ ë¶€ì‚¬
  ë§›ìˆì—ˆì–´ìš” â†’ í˜•ìš©ì‚¬
  ë˜      â†’ ë¶€ì‚¬
  ì‹œí‚¬ê²Œìš”  â†’ ë™ì‚¬
```

---

### 2-2. í‚¤ì›Œë“œ ë¶„ì„ â€” "ì‚¬ëŒë“¤ì´ ë­˜ ë§í•˜ê³  ìˆë‚˜?"

**í•œ ì¤„ ì •ì˜**: í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ ë‹¨ì–´(ëª…ì‚¬ ìœ„ì£¼)ë¥¼ ì¶”ì¶œí•˜ê³  ë¹ˆë„ë¥¼ ë¶„ì„í•˜ëŠ” ê¸°ìˆ 

**ì‹¤ì œ ì„œë¹„ìŠ¤ ì ìš© ì‚¬ë¡€**

- ì•± ë¦¬ë·° 1ë§Œ ê±´ â†’ ìì£¼ ì–¸ê¸‰ë˜ëŠ” ë¶ˆë§Œ í‚¤ì›Œë“œ ìë™ íŒŒì•…
- SNS ëª¨ë‹ˆí„°ë§ â†’ ë¸Œëœë“œ ê´€ë ¨ ì‹¤ì‹œê°„ ì´ìŠˆ ê°ì§€
- ê²€ìƒ‰ ë¡œê·¸ ë¶„ì„ â†’ ì‚¬ìš©ìê°€ ì‹¤ì œë¡œ ì°¾ëŠ” ê²ƒ íŒŒì•…
- ë‰´ìŠ¤ íŠ¸ë Œë“œ ë¶„ì„ â†’ ìš”ì¦˜ í™”ì œì˜ ì£¼ì œ íŒŒì•…

**ì²˜ë¦¬ íë¦„**

```mermaid
flowchart TD
    A[í…ìŠ¤íŠ¸ ìˆ˜ì§‘]
    B["í˜•íƒœì†Œ ë¶„ì„ (ëª…ì‚¬ë§Œ ì¶”ì¶œ)"]
    C["ë¶ˆìš©ì–´ ì œê±° (ì´ê²ƒ, ì €ê²ƒ, ê·¸ê²ƒ, ë“±, ë°â€¦)"]
    D[ë‹¨ì–´ ë¹ˆë„ ì§‘ê³„]
    E["ì‹œê°í™” (ì›Œë“œí´ë¼ìš°ë“œ, ë§‰ëŒ€ê·¸ë˜í”„)"]
    A --> B --> C --> D --> E
```

**ì›Œë“œí´ë¼ìš°ë“œ ì˜ˆì‹œ â€” ì¹´í˜ ë¦¬ë·° ë¶„ì„**

```
ìì£¼ ë‚˜ì˜¨ ë‹¨ì–´: ì»¤í”¼(523), ë¶„ìœ„ê¸°(412), ì¼€ì´í¬(389), 
               ì¹œì ˆ(301), ì›¨ì´íŒ…(287), ê°€ê²©(245), 
               ì£¼ì°¨(198), ì½˜ì„¼íŠ¸(187), ì¡°ìš©(156)...
```

â†’ "ì›¨ì´íŒ…"ê³¼ "ì£¼ì°¨"ê°€ ìƒìœ„ì— ìˆë‹¤ë©´? ìš´ì˜íŒ€ì— ì¦‰ì‹œ ì•¡ì…˜ í¬ì¸íŠ¸!

---

### 2-3. ì—°ê´€ì–´ ë¶„ì„ â€” "í•¨ê»˜ ë‚˜ì˜¤ëŠ” ë‹¨ì–´ëŠ”?"

**í•œ ì¤„ ì •ì˜**: íŠ¹ì • í‚¤ì›Œë“œì™€ í•¨ê»˜ ìì£¼ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ë“¤ì˜ ê´€ê³„ë¥¼ ë¶„ì„í•˜ëŠ” ê¸°ìˆ   
*(ë™ì‹œì¶œí˜„ ë¶„ì„, Co-occurrence Analysis)*

**ì‹¤ì œ ì„œë¹„ìŠ¤ ì ìš© ì‚¬ë¡€**

- ê²€ìƒ‰ ìë™ì™„ì„±: "ì•„ì´í°" ê²€ìƒ‰ ì‹œ â†’ "ì¼€ì´ìŠ¤", "ì¶©ì „ê¸°", "í• ë¶€" ì—°ê´€ ì œì‹œ
- ìƒí’ˆ ì¶”ì²œ: "ìš´ë™í™”" êµ¬ë§¤ì â†’ "ì–‘ë§", "ê¹”ì°½", "ìŠ¤í¬ì¸ ë°±" í•¨ê»˜ ë…¸ì¶œ
- ë¦¬ìŠ¤í¬ ëª¨ë‹ˆí„°ë§: ë¸Œëœë“œëª…ê³¼ í•¨ê»˜ "í™˜ë¶ˆ", "ë¶ˆëŸ‰", "AS" ì—°ê´€ì–´ ê¸‰ì¦ ê°ì§€
- ì½˜í…ì¸  ê¸°íš: "ê±´ê°•ì‹ë‹¨"ê³¼ ì—°ê´€ëœ "ê°„í—ì ë‹¨ì‹", "ì €íƒ„ê³ ì§€" íŠ¸ë Œë“œ íŒŒì•…

**ì›ë¦¬**

```
ë¬¸ì„œë“¤ì—ì„œ ê°™ì€ ë¬¸ì¥/ë¬¸ë‹¨ ë‚´ í•¨ê»˜ ë‚˜íƒ€ë‚˜ëŠ” ë‹¨ì–´ ìŒì„ ì§‘ê³„

"ì•„ì´í° ì¼€ì´ìŠ¤ ì¶”ì²œí•´ì£¼ì„¸ìš”" â†’ (ì•„ì´í°, ì¼€ì´ìŠ¤) ê³µë™ ì¶œí˜„ +1
"ì•„ì´í° ê°€ê²©ì´ ë„ˆë¬´ ë¹„ì‹¸ìš”" â†’ (ì•„ì´í°, ê°€ê²©) ê³µë™ ì¶œí˜„ +1
...
â†’ ì•„ì´í°ê³¼ ê°€ì¥ ë§ì´ í•¨ê»˜ ë‚˜ì˜¨ ë‹¨ì–´ë“¤: ì¼€ì´ìŠ¤(1,203), ê°€ê²©(987), ì¶©ì „(876)...
```

---

### 2-4. ë¬¸ì„œ ë¶„ë¥˜ (Document Classification) â€” "ì´ ê¸€ì€ ì–´ë–¤ ì¢…ë¥˜?"

**í•œ ì¤„ ì •ì˜**: í…ìŠ¤íŠ¸ ë¬¸ì„œë¥¼ ë¯¸ë¦¬ ì •í•´ì§„ ì¹´í…Œê³ ë¦¬ë¡œ ìë™ ë¶„ë¥˜í•˜ëŠ” ê¸°ìˆ 

**ê°ì„± ë¶„ì„(Sentiment Analysis)ì´ ëŒ€í‘œì  ì‚¬ë¡€**

```
"ë°°ì†¡ì´ ë¹ ë¥´ê³  ìƒí’ˆë„ ì¢‹ì•„ìš”!" â†’ ê¸ì • (Positive) ğŸ˜Š
"í¬ì¥ì´ ì—‰ë§ì´ê³  ASë„ ì•ˆ ë¼ìš”" â†’ ë¶€ì • (Negative) ğŸ˜ 
"í‰ë²”í•œ ì œí’ˆì´ì—ìš”"             â†’ ì¤‘ë¦½ (Neutral)  ğŸ˜
```

**ì‹¤ì œ ì„œë¹„ìŠ¤ ì ìš© ì‚¬ë¡€**

| ì„œë¹„ìŠ¤ | ë¶„ë¥˜ ê¸°ì¤€ | í™œìš© |
|--------|-----------|------|
| ê³ ê°ì„¼í„° | ë¬¸ì˜ ìœ í˜• (ë°°ì†¡/ê²°ì œ/êµí™˜/ê¸°íƒ€) | ë‹´ë‹¹ì ìë™ ë°°ì • |
| ë‰´ìŠ¤ í”Œë«í¼ | ì„¹ì…˜ (ì •ì¹˜/ê²½ì œ/ìŠ¤í¬ì¸ /ì—°ì˜ˆ) | ìë™ ì¹´í…Œê³ ë¦¬ ê²Œì‹œ |
| ì‡¼í•‘ëª° | ë¦¬ë·° ê°ì„± (ê¸/ë¶€ì •) | ë³„ì  ë³´ì™„ ì§€í‘œ |
| HR ì‹œìŠ¤í…œ | ì´ë ¥ì„œ ì§ë¬´ ì í•©ë„ | 1ì°¨ í•„í„°ë§ |

**ê³ ì „ì  ë°©ë²• (TF-IDF + ë¨¸ì‹ ëŸ¬ë‹ ë¶„ë¥˜ê¸°)**

```
1. í…ìŠ¤íŠ¸ â†’ í˜•íƒœì†Œ ë¶„ì„ â†’ ëª…ì‚¬/í˜•ìš©ì‚¬ ì¶”ì¶œ
2. TF-IDFë¡œ ë‹¨ì–´ ì¤‘ìš”ë„ ìˆ˜ì¹˜í™” (ë²¡í„° ë³€í™˜)
3. ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ, SVM, ëœë¤í¬ë ˆìŠ¤íŠ¸ ë“±ìœ¼ë¡œ ë¶„ë¥˜ í•™ìŠµ
4. ìƒˆ í…ìŠ¤íŠ¸ â†’ ë™ì¼ ë³€í™˜ â†’ ë¶„ë¥˜ ê²°ê³¼ ì¶œë ¥
```

> ğŸ’¡ **LLMê³¼ì˜ ë¹„êµ**: GPTì—ê²Œ "ì´ ë¦¬ë·° ê¸ì •/ë¶€ì • ë¶„ë¥˜í•´ì¤˜"ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.  
> í•˜ì§€ë§Œ ë¦¬ë·° 100ë§Œ ê±´ ì²˜ë¦¬ ë¹„ìš©ê³¼ ì†ë„ë¥¼ ìƒê°í•˜ë©´? â†’ ê³ ì „ì  ë¶„ë¥˜ ëª¨ë¸ì´ ì••ë„ì ìœ¼ë¡œ ìœ ë¦¬í•©ë‹ˆë‹¤.

---

### 2-5. ë¬¸ì„œ êµ°ì§‘í™” (Document Clustering) â€” "ë¹„ìŠ·í•œ ê¸€ë¼ë¦¬ ë¬¶ì–´ìš”"

**í•œ ì¤„ ì •ì˜**: ì •ë‹µ ì—†ì´ ë‚´ìš©ì´ ìœ ì‚¬í•œ ë¬¸ì„œë“¤ì„ ìë™ìœ¼ë¡œ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ëŠ” ê¸°ìˆ 

**ì‹¤ì œ ì„œë¹„ìŠ¤ ì ìš© ì‚¬ë¡€**

- ë‰´ìŠ¤ ìë™ í† í”½ ê·¸ë£¹í™”: ê°™ì€ ì‚¬ê±´ì˜ ê¸°ì‚¬ë“¤ì„ í•˜ë‚˜ì˜ í´ëŸ¬ìŠ¤í„°ë¡œ
- VOC(ê³ ê° ëª©ì†Œë¦¬) ë¶„ì„: ìˆ˜ì²œ ê±´ì˜ ë¶ˆë§Œ ê¸€ì„ ìë™ìœ¼ë¡œ ì´ìŠˆë³„ ê·¸ë£¹í™”
- íŠ¹í—ˆ ë¶„ì„: ìœ ì‚¬ ê¸°ìˆ  íŠ¹í—ˆ ë¬¸ì„œ ìë™ êµ°ì§‘í™”
- ì»¤ë®¤ë‹ˆí‹° ë¶„ì„: ê²Œì‹œê¸€ì„ ì£¼ì œë³„ë¡œ ìë™ ë¶„ë¥˜

**ì²˜ë¦¬ íë¦„**

```mermaid
flowchart LR
    A[ë¬¸ì„œ ìˆ˜ì§‘] --> B[í˜•íƒœì†Œ ë¶„ì„] --> C[TF-IDF ë²¡í„° ë³€í™˜]
    C --> D[K-Means êµ°ì§‘í™”] --> E[ëŒ€í‘œ í‚¤ì›Œë“œ ì¶”ì¶œ] --> F["ì´ë¦„ ë¶™ì´ê¸° (ì‚¬ëŒì´)"]
```

---

### 2-6. í‚¤ì›Œë“œ ë„¤íŠ¸ì›Œí¬ ë¶„ì„ (Keyword Network Analysis)

**í•œ ì¤„ ì •ì˜**: ë‹¨ì–´ë“¤ì˜ ë™ì‹œì¶œí˜„ ê´€ê³„ë¥¼ ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ë¡œ ì‹œê°í™”í•´ ê°œë… êµ¬ì¡°ì™€ ì˜í–¥ë ¥ì„ ë¶„ì„í•˜ëŠ” ê¸°ìˆ 

**ì—°ê´€ì–´ ë¶„ì„ì˜ ì§„í™”ëœ í˜•íƒœ** â€” ë‹¨ìˆœí•œ "í•¨ê»˜ ë‚˜ì˜¨ ë‹¨ì–´ ëª©ë¡"ì„ ë„˜ì–´, ì–´ë–¤ ë‹¨ì–´ê°€ í—ˆë¸Œ(ì¤‘ì‹¬)ì¸ì§€, ì–´ë–¤ ë‹¨ì–´ ê·¸ë£¹ì´ í´ëŸ¬ìŠ¤í„°ë¥¼ ì´ë£¨ëŠ”ì§€ê¹Œì§€ íŒŒì•…í•©ë‹ˆë‹¤.

**í•µì‹¬ ê°œë…**

- **ë…¸ë“œ(Node)**: ë‹¨ì–´ (í¬ê¸° = ì¤‘ìš”ë„/ë¹ˆë„)
- **ì—£ì§€(Edge)**: ë‘ ë‹¨ì–´ì˜ ë™ì‹œì¶œí˜„ (êµµê¸° = ì—°ê´€ ê°•ë„)
- **í—ˆë¸Œ(Hub)**: ë§ì€ ë‹¨ì–´ì™€ ì—°ê²°ëœ í•µì‹¬ ê°œë…
- **í´ëŸ¬ìŠ¤í„°**: ì„œë¡œ ë°€ì ‘í•˜ê²Œ ì—°ê²°ëœ ë‹¨ì–´ ê·¸ë£¹

"AI ì·¨ì—…" ê´€ë ¨ ì»¤ë®¤ë‹ˆí‹° ë¶„ì„ ê²°ê³¼:

```mermaid
graph LR
    subgraph cA["í´ëŸ¬ìŠ¤í„° A: ê¸°ìˆ "]
        n1["ë”¥ëŸ¬ë‹"]
        n2["íŒŒì´ì¬"]
        n3["AI"]
    end
    subgraph cB["í´ëŸ¬ìŠ¤í„° B: ì·¨ì—…"]
        n4["ì·¨ì—…"]
        n5["í”„ë¡œì íŠ¸"]
        n6["í¬íŠ¸í´ë¦¬ì˜¤"]
    end
    subgraph cC["í´ëŸ¬ìŠ¤í„° C: êµìœ¡"]
        n7["ë¶€íŠ¸ìº í”„"]
        n8["êµ­ë¹„ì§€ì›"]
    end
    n1 --- n3
    n1 --- n2
    n3 --- n4
    n3 --- n5
    n2 --- n5
    n5 --- n6
    n4 --- n6
    n6 --- n7
    n7 --- n8
```

**ë„¤íŠ¸ì›Œí¬ ì§€í‘œ í•´ì„**

| ì§€í‘œ | ì˜ë¯¸ | í™œìš© |
|------|------|------|
| ì—°ê²° ì¤‘ì‹¬ì„± (Degree) | ëª‡ ê°œ ë‹¨ì–´ì™€ ì—°ê²°ë˜ì—ˆë‚˜ | í•µì‹¬ í‚¤ì›Œë“œ íŒŒì•… |
| ë§¤ê°œ ì¤‘ì‹¬ì„± (Betweenness) | ë‹¤ë¥¸ ë‹¨ì–´ë“¤ì„ ì‡ëŠ” ë‹¤ë¦¬ ì—­í•  | ì´ìŠˆ ì—°ê²°ê³ ë¦¬ íŒŒì•… |
| í´ëŸ¬ìŠ¤í„° ê³„ìˆ˜ | ì£¼ë³€ ë‹¨ì–´ë“¤ë¼ë¦¬ ì–¼ë§ˆë‚˜ ì—°ê²°ë˜ë‚˜ | í† í”½ ê·¸ë£¹ ê²½ê³„ íŒŒì•… |

**ì‹¤ì œ ì„œë¹„ìŠ¤ ì ìš© ì‚¬ë¡€**

- ë¸Œëœë“œ ì¸ì‹ ì§€ë„: ë‚´ ë¸Œëœë“œ ì£¼ë³€ì— í˜•ì„±ëœ ê°œë… êµ°ì§‘ êµ¬ì¡° íŒŒì•…
- íŠ¸ë Œë“œ í™•ì‚° ë¶„ì„: ì´ìŠˆê°€ ì–´ë–¤ ê°œë…ë“¤ì„ ê±°ì³ í™•ì‚°ë˜ëŠ”ì§€ ê²½ë¡œ ì¶”ì 
- í•™ìˆ /íŠ¹í—ˆ ë¶„ì„: ì—°êµ¬ í‚¤ì›Œë“œ ë„¤íŠ¸ì›Œí¬ë¡œ ê¸°ìˆ  íë¦„ê³¼ ê³µë°± ì˜ì—­ ì‹œê°í™”
- ì†Œë¹„ì ì¸ì‹ ì¡°ì‚¬: ì„¤ë¬¸Â·ì¸í„°ë·° í…ìŠ¤íŠ¸ì—ì„œ ì¸ì‹ êµ¬ì¡° ë°œê²¬
- ê²½ìŸì‚¬ ëª¨ë‹ˆí„°ë§: ê²½ìŸ ë¸Œëœë“œì™€ ìì‚¬ ë¸Œëœë“œì˜ ì—°ê´€ì–´ ë„¤íŠ¸ì›Œí¬ ë¹„êµ

**ë„êµ¬**

```
Python: networkx + matplotlib / pyvis (ì¸í„°ë™í‹°ë¸Œ)
ì˜¨ë¼ì¸: í…ìŠ¤í†°(Textom), NodeXL
ì‹œê°í™”: Gephi (ì „ë¬¸ ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ë„êµ¬)
```

**ê¸°íšìÂ·ë””ìì´ë„ˆê°€ ì•Œì•„ì•¼ í•  í¬ì¸íŠ¸**

- ë„¤íŠ¸ì›Œí¬ ì‹œê°í™”ëŠ” ê·¸ ìì²´ë¡œ ê°•ë ¥í•œ ìŠ¤í† ë¦¬í…”ë§ ë„êµ¬ì…ë‹ˆë‹¤ (ë³´ê³ ì„œ, ë°œí‘œìë£Œì— í™œìš©)
- ì¤‘ì‹¬ì„±ì´ ë†’ì€ ë‹¨ì–´ = í•´ë‹¹ ë‹´ë¡ ì˜ í•µì‹¬ ì˜ì œ â†’ ì „ëµ ìˆ˜ë¦½ì˜ ì‹œì‘ì 
- ë¶„ë¦¬ëœ í´ëŸ¬ìŠ¤í„°ê°€ ìˆë‹¤ë©´ ì„œë¡œ ë‹¤ë¥¸ ì‚¬ìš©ì ì§‘ë‹¨ì´ë‚˜ ë¬¸í™”ê¶Œì„ ì˜ë¯¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

---

### 2-7. í† í”½ ë¶„ì„ (Topic Modeling / LDA)

**í•œ ì¤„ ì •ì˜**: ëŒ€ëŸ‰ì˜ ë¬¸ì„œ ì§‘í•©ì—ì„œ ìˆ¨ê²¨ì§„ ì£¼ì œ(í† í”½)ë¥¼ ìë™ìœ¼ë¡œ ë°œê²¬í•˜ëŠ” ê¸°ìˆ   
*(ê°€ì¥ ëŒ€í‘œì  ì•Œê³ ë¦¬ì¦˜: LDA â€“ Latent Dirichlet Allocation)*

**êµ°ì§‘í™”ì™€ì˜ ì°¨ì´ì **

```
ë¬¸ì„œ êµ°ì§‘í™”: í•˜ë‚˜ì˜ ë¬¸ì„œ = í•˜ë‚˜ì˜ í´ëŸ¬ìŠ¤í„° (ë”± í•˜ë‚˜ì˜ ê·¸ë£¹ì— ì†Œì†)
í† í”½ ë¶„ì„:  í•˜ë‚˜ì˜ ë¬¸ì„œ = ì—¬ëŸ¬ í† í”½ì˜ í˜¼í•© (í™•ë¥  ë¶„í¬ë¡œ í‘œí˜„)

ì˜ˆì‹œ: "AI ìŠ¤íƒ€íŠ¸ì—… íˆ¬ì í˜„í™©"ì´ë¼ëŠ” ê¸°ì‚¬
  â†’ í† í”½ A(AI ê¸°ìˆ ): 40%  
  â†’ í† í”½ B(ìŠ¤íƒ€íŠ¸ì—… ìƒíƒœê³„): 35%  
  â†’ í† í”½ C(íˆ¬ì/ê¸ˆìœµ): 25%
```

**í•µì‹¬ ì›ë¦¬ (LDA)**

```
ê°€ì •: ê° ë¬¸ì„œëŠ” ì—¬ëŸ¬ í† í”½ì´ ì„ì—¬ ìˆê³ ,
      ê° í† í”½ì€ íŠ¹ì • ë‹¨ì–´ë“¤ì´ ìì£¼ ë“±ì¥í•˜ëŠ” ë¶„í¬ë‹¤.

ì…ë ¥: ë‰´ìŠ¤ ê¸°ì‚¬ 10,000ê±´, í† í”½ ìˆ˜ K=5 ì§€ì •
ì¶œë ¥:
  í† í”½ 1: ê²½ì œ(0.18), ê¸ˆë¦¬(0.15), ë¶€ë™ì‚°(0.12), ë¬¼ê°€(0.10)...
  í† í”½ 2: AI(0.20), ë°˜ë„ì²´(0.17), ìŠ¤íƒ€íŠ¸ì—…(0.13), íˆ¬ì(0.11)...
  í† í”½ 3: ì„ ê±°(0.22), ì •ë‹¹(0.16), í›„ë³´(0.14), ê³µì•½(0.09)...
  í† í”½ 4: ì•¼êµ¬(0.24), ìš°ìŠ¹(0.18), ì„ ìˆ˜(0.15), ê²½ê¸°(0.12)...
  í† í”½ 5: ê¸°í›„(0.19), íƒ„ì†Œ(0.16), ì¬ìƒì—ë„ˆì§€(0.13), í™˜ê²½(0.11)...
```

**ì‹¤ì œ ì„œë¹„ìŠ¤ ì ìš© ì‚¬ë¡€**

| ì„œë¹„ìŠ¤ | í™œìš© ë°©ë²• | íš¨ê³¼ |
|--------|-----------|------|
| ë‰´ìŠ¤ í”Œë«í¼ | ê¸°ì‚¬ í† í”½ ìë™ ë¶„ë¥˜ ë° íŠ¸ë Œë“œ ì¶”ì  | ì—ë””í„° ì‘ì—… ì‹œê°„ ë‹¨ì¶• |
| ê³ ê°ì„¼í„° | VOC í† í”½ ë³€í™” ëª¨ë‹ˆí„°ë§ | ì´ìŠˆ ì¡°ê¸° ê°ì§€ |
| ë¦¬ì„œì¹˜ ê¸°ê´€ | ì†Œì…œ ë°ì´í„°ì˜ ì—¬ë¡  í† í”½ ë¶„ì„ | ì •ì±…/ì „ëµ ìˆ˜ë¦½ ê·¼ê±° |
| ì»¤ë¨¸ìŠ¤ | ìƒí’ˆ ë¦¬ë·° í† í”½ ë¶„ì„ â†’ ê°œì„ ì  ë„ì¶œ | ì œí’ˆ ê°œë°œ ë°©í–¥ ì„¤ì • |
| í•™ìˆ  | ë…¼ë¬¸ í† í”½ íŠ¸ë Œë“œ ë¶„ì„ | ì—°êµ¬ ê³µë°± ì˜ì—­ ë°œê²¬ |

**ì²˜ë¦¬ íë¦„**

```mermaid
flowchart TD
    A["í…ìŠ¤íŠ¸ ìˆ˜ì§‘ (ë‰´ìŠ¤, ë¦¬ë·°, SNS ë“±)"]
    B["í˜•íƒœì†Œ ë¶„ì„ â†’ ëª…ì‚¬ ì¶”ì¶œ â†’ ë¶ˆìš©ì–´ ì œê±°"]
    C["ë‹¨ì–´-ë¬¸ì„œ í–‰ë ¬ (DTM) ìƒì„±"]
    D["LDA ëª¨ë¸ í•™ìŠµ (í† í”½ ìˆ˜ K ì§€ì •)"]
    E["ê° í† í”½ì˜ ëŒ€í‘œ í‚¤ì›Œë“œ ì¶”ì¶œ"]
    F["í† í”½ ì´ë¦„ ë¶€ì—¬ (ì‚¬ëŒì´ í•´ì„)"]
    G["ì‹œê°í™”: pyLDAvis, ì›Œë“œí´ë¼ìš°ë“œ"]
    A --> B --> C --> D --> E --> F --> G
```

**Python ì½”ë“œ ì˜ˆì‹œ**

```python
# pip install gensim pyLDAvis kiwipiepy matplotlib

import platform
from kiwipiepy import Kiwi
from gensim import corpora, models
import pyLDAvis.gensim_models
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

# í”Œë«í¼ë³„ í•œê¸€ í°íŠ¸ ì„¤ì •
_system = platform.system()
if _system == 'Darwin':
    plt.rcParams['font.family'] = 'AppleGothic'
elif _system == 'Windows':
    plt.rcParams['font.family'] = 'Malgun Gothic'
else:  # Linux ë“±
    _nanum = [f.name for f in fm.fontManager.ttflist if 'Nanum' in f.name]
    if _nanum:
        plt.rcParams['font.family'] = _nanum[0]
plt.rcParams['axes.unicode_minus'] = False

# 1. í˜•íƒœì†Œ ë¶„ì„ (ëª…ì‚¬ ì¶”ì¶œ)
print("[1/5] í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™” ì¤‘...")
kiwi = Kiwi()

def extract_nouns(text):
    result = kiwi.analyze(text)
    nouns = [token.form for token in result[0][0]
             if token.tag.startswith('NN') and len(token.form) > 1]
    return nouns

# 2. ìƒ˜í”Œ ë¬¸ì„œ (2025ë…„ êµ­ë‚´ ì£¼ìš” ë‰´ìŠ¤ í—¤ë“œë¼ì¸ 50ê±´)
docs = [
    # AI Â· ê¸°ìˆ 
    "ì±—GPT êµ¬ë… ê²°ì œ ê¸‰ì¦, êµ­ë‚´ ìƒì„±í˜• AI ì‹œì¥ í­ë°œì  ì„±ì¥",
    "ì‚¼ì„±ì „ì HBM ë°˜ë„ì²´ ì—”ë¹„ë””ì•„ ë‚©í’ˆ ìŠ¹ì¸, ì£¼ê°€ ê¸‰ë“±",
    # ê²½ì œ Â· ê¸ˆìœµ
    "ì½”ìŠ¤í”¼ 4000ì„  ëŒíŒŒ, ì‚¬ìƒ ì²« 'ì‚¬ì²œí”¼' ì‹œëŒ€ ê°œë§‰",
    "ì¥ë°”êµ¬ë‹ˆ ë¬¼ê°€ 5ë…„ ìƒˆ 23% ê¸‰ë“±, ì„œë¯¼ ê°€ê³„ ë¶€ë‹´ ê°€ì¤‘",
    # í™˜ê²½ Â· ì—ë„ˆì§€
    "ì§€êµ¬ í‰ê·  ê¸°ì˜¨ íŒŒë¦¬í˜‘ì•½ ëª©í‘œ 1.5ë„ ì´ˆê³¼, ê¸°í›„ ìœ„ê¸° ê²½ë³´",
    "ì •ë¶€ ì¬ìƒì—ë„ˆì§€ í™•ëŒ€ ë¡œë“œë§µ ë°œí‘œ, 2030ë…„ íƒœì–‘ê´‘Â·í’ë ¥ 40% ëª©í‘œ",
    # ìŠ¤í¬ì¸ 
    "í•˜ì–¼ë¹ˆ ë™ê³„ ì•„ì‹œì•ˆê²Œì„ ê¸ˆë©”ë‹¬ 16ê°œ, í•œêµ­ ì¢…í•© 2ìœ„ ì¾Œê±°",
    # ... (ì´ 50ê±´ â€” script/topic_model.py ì°¸ì¡°)
]

# 3. ì „ì²˜ë¦¬
print(f"\n[2/5] í˜•íƒœì†Œ ë¶„ì„ ì¤‘... (ë¬¸ì„œ {len(docs)}ê±´)")
tokenized = [extract_nouns(doc) for doc in docs]

# 4. ì‚¬ì „ ë° í–‰ë ¬ ìƒì„±
print(f"\n[3/5] ë‹¨ì–´ ì‚¬ì „ ë° ë¬¸ì„œ-ë‹¨ì–´ í–‰ë ¬ ìƒì„± ì¤‘...")
dictionary = corpora.Dictionary(tokenized)
corpus = [dictionary.doc2bow(doc) for doc in tokenized]
print(f"      ì™„ë£Œ â€” ê³ ìœ  ë‹¨ì–´ {len(dictionary)}ê°œ, ë¬¸ì„œ {len(corpus)}ê±´")

# 5. LDA ëª¨ë¸ í•™ìŠµ
print(f"\n[4/5] LDA ëª¨ë¸ í•™ìŠµ ì¤‘... (í† í”½ 6ê°œ, passes=50)")
lda_model = models.LdaModel(
    corpus=corpus,
    id2word=dictionary,
    num_topics=6,   # í† í”½ ìˆ˜: AI/ê¸°ìˆ , ê²½ì œ, ë¶€ë™ì‚°, í™˜ê²½, ì‚¬íšŒ, ìŠ¤í¬ì¸ /ì •ì¹˜
    passes=50,
    random_state=42
)

# 6. í† í”½ ì¶œë ¥
print(f"\n[5/5] ê²°ê³¼ ì¶œë ¥ ë° ì‹œê°í™”\n")
for i, topic in lda_model.print_topics(num_words=7):
    print(f"í† í”½ {i+1}: {topic}")

# 7. ì¸í„°ë™í‹°ë¸Œ ì‹œê°í™”
vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)
pyLDAvis.save_html(vis, 'lda_result.html')

# 8. ë¶„ì„ ë¦¬í¬íŠ¸ ì €ì¥ (lda_analysis.md)
with open('lda_analysis.md', 'w', encoding='utf-8') as f:
    f.write(f"# LDA í† í”½ ëª¨ë¸ë§ ë¶„ì„ ë¦¬í¬íŠ¸\n\n")
    f.write(f"- ë¶„ì„ ë¬¸ì„œ ìˆ˜: **{len(docs)}ê±´**\n")
    f.write(f"- í† í”½ ìˆ˜: **{lda_model.num_topics}ê°œ**\n\n")
    for i in range(lda_model.num_topics):
        f.write(f"## í† í”½ {i+1}\n")
        for word, prob in lda_model.show_topic(i, topn=10):
            f.write(f"- {word}: {prob:.4f}\n")
        f.write("\n")
```

**í† í”½ ë¶„ì„ ê²°ê³¼ í•´ì„ ë°©ë²•**

```
ì¢‹ì€ í† í”½ ëª¨ë¸ì˜ íŠ¹ì§•:
  âœ… ê° í† í”½ì˜ í‚¤ì›Œë“œë“¤ì´ ì˜ë¯¸ì ìœ¼ë¡œ ì¼ê´€ë¨
  âœ… í† í”½ ê°„ ì¤‘ë³µ í‚¤ì›Œë“œê°€ ì ìŒ
  âœ… ë¹„ì¦ˆë‹ˆìŠ¤ íŒ€ì´ í† í”½ì— ì´ë¦„ ë¶™ì´ê¸° ì‰¬ì›€

ë‚˜ìœ í† í”½ ëª¨ë¸ì˜ íŠ¹ì§•:
  âŒ í† í”½ í‚¤ì›Œë“œê°€ ì¡ë‹¤í•˜ê³  ì—°ê´€ì„± ì—†ìŒ
  âŒ ì—¬ëŸ¬ í† í”½ì´ ê±°ì˜ ê°™ì€ í‚¤ì›Œë“œë¥¼ ê°€ì§
  â†’ í•´ê²°: K ê°’ ì¡°ì •, ë¶ˆìš©ì–´ ë³´ì™„, ë°ì´í„° ì¶”ê°€
```

**ê¸°íšìÂ·ë””ìì´ë„ˆê°€ ì•Œì•„ì•¼ í•  í¬ì¸íŠ¸**

- í† í”½ ìˆ˜(K)ëŠ” ì•Œê³ ë¦¬ì¦˜ì´ ì •í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ â€” ì—¬ëŸ¬ Kë¥¼ ì‹œë„í•´ë³´ê³  ì‚¬ëŒì´ íŒë‹¨í•´ì•¼ í•©ë‹ˆë‹¤
- í† í”½ì— ì´ë¦„ì„ ë¶™ì´ëŠ” ê²ƒì€ ë°˜ë“œì‹œ ë„ë©”ì¸ ì „ë¬¸ê°€ê°€ í•´ì•¼ í•©ë‹ˆë‹¤
- ì‹œê°„ì¶•ì„ ì¶”ê°€í•˜ë©´ **í† í”½ íŠ¸ë Œë“œ ë¶„ì„** ê°€ëŠ¥ â†’ "3ê°œì›” ì „ vs ì§€ê¸ˆ ì£¼ìš” ì´ìŠˆ ë³€í™”"
- LLMê³¼ì˜ ì¡°í•©: LDAë¡œ í† í”½ ì¶”ì¶œ â†’ GPTë¡œ í† í”½ ì„¤ëª…ë¬¸ ìë™ ìƒì„±í•˜ë©´ ê°•ë ¥í•œ ìë™í™” ê°€ëŠ¥

---

## Part 3. ì‹¤ìŠµ ë°ëª¨ â€” MNIST í•„ê¸° ìˆ«ì ì¸ì‹

> ì´ ë°ëª¨ëŠ” ê³ ì „ì  ë¨¸ì‹ ëŸ¬ë‹ì˜ **ë¶„ë¥˜(Classification)** ë¥¼ ê°€ì¥ ì§ê´€ì ìœ¼ë¡œ ì²´í—˜í•˜ëŠ” ì˜ˆì œì…ë‹ˆë‹¤.

### MNIST ë°ì´í„°ì…‹ì´ë€?

```
- 0~9 í•„ê¸° ìˆ«ì ì´ë¯¸ì§€ 70,000ì¥ (28Ã—28 í”½ì…€)
- í›ˆë ¨ìš© 60,000ì¥ + í…ŒìŠ¤íŠ¸ìš© 10,000ì¥
- 1998ë…„ ê³µê°œ, ë¨¸ì‹ ëŸ¬ë‹ì˜ "Hello World"
- ê° ì´ë¯¸ì§€ì— ì •ë‹µ ë ˆì´ë¸”(0~9)ì´ ìˆìŒ â†’ ì§€ë„í•™ìŠµ(ë¶„ë¥˜)
```

### ì–´ë–»ê²Œ ë™ì‘í•˜ëŠ”ê°€?

```mermaid
flowchart TD
    A["ì…ë ¥: 28Ã—28 í”½ì…€ ì´ë¯¸ì§€"]
    B["í”½ì…€ê°’ì„ 784ê°œ ìˆ«ì ë°°ì—´ë¡œ ë³€í™˜\nì˜ˆ: [0, 0, 128, 255, 200, 0, â€¦]"]
    C["ë¶„ë¥˜ ëª¨ë¸ (Random Forest / SVM / CNN)"]
    D["ì¶œë ¥: 'ì´ ì´ë¯¸ì§€ëŠ” 7ì¼ í™•ë¥  98.3%'"]
    A --> B --> C --> D
```

### ì‹¤ì œ êµ¬í˜„ ì½”ë“œ ìŠ¤ë‹ˆí« (Python)

```python
# í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
# pip install scikit-learn matplotlib

import platform
from sklearn.datasets import fetch_openml
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

# í”Œë«í¼ë³„ í•œê¸€ í°íŠ¸ ì„¤ì • (ê·¸ë˜í”„ ì œëª© í•œê¸€ ê¹¨ì§ ë°©ì§€)
_system = platform.system()
if _system == 'Darwin':
    plt.rcParams['font.family'] = 'AppleGothic'
elif _system == 'Windows':
    plt.rcParams['font.family'] = 'Malgun Gothic'
else:  # Linux ë“±
    _nanum = [f.name for f in fm.fontManager.ttflist if 'Nanum' in f.name]
    if _nanum:
        plt.rcParams['font.family'] = _nanum[0]
plt.rcParams['axes.unicode_minus'] = False

# 1. ë°ì´í„° ë¡œë“œ
print("ë°ì´í„° ë¡œë”© ì¤‘...")
mnist = fetch_openml('mnist_784', version=1, as_frame=False)
X, y = mnist.data, mnist.target

# 2. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„ë¦¬ (60,000 í•™ìŠµ / 10,000 í…ŒìŠ¤íŠ¸)
X_train, X_test = X[:60000], X[60000:]
y_train, y_test = y[:60000], y[60000:]

# 3. í”½ì…€ê°’ ì •ê·œí™” (0~255 â†’ 0~1)
X_train = X_train / 255.0
X_test = X_test / 255.0

# 4. ëª¨ë¸ í•™ìŠµ
print("ëª¨ë¸ í•™ìŠµ ì¤‘...")
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# 5. ì˜ˆì¸¡ ë° ì •í™•ë„ ì¸¡ì •
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"ì •í™•ë„: {accuracy:.4f}")  # ì•½ 97% ë‹¬ì„±!

# 6. ì‹œê°í™”: ì˜ˆì¸¡ ê²°ê³¼ í™•ì¸
fig, axes = plt.subplots(2, 5, figsize=(12, 5))
for i, ax in enumerate(axes.flat):
    ax.imshow(X_test[i].reshape(28, 28), cmap='gray')
    ax.set_title(f"ì˜ˆì¸¡: {y_pred[i]}\nì‹¤ì œ: {y_test[i]}")
    ax.axis('off')
plt.tight_layout()
plt.show()
```

### ê²°ê³¼ í•´ì„

```
âœ… ì •í™•ë„ ì•½ 97% â€” ì‚¬ëŒ 100ì¥ ì¤‘ 97ì¥ì€ ë§í˜
âŒ í‹€ë¦¬ëŠ” ê²½ìš° ì˜ˆì‹œ:
   - ì†ê¸€ì”¨ê°€ ë„ˆë¬´ ë…íŠ¹í•œ ê²½ìš°
   - 4ì™€ 9, 1ê³¼ 7 í˜¼ë™
   - ê¸°ìš¸ì–´ì§€ê±°ë‚˜ í¬ê¸°ê°€ ë§¤ìš° ë‹¤ë¥¸ ê²½ìš°
```

### ê¸°íšìÂ·ë””ìì´ë„ˆë¥¼ ìœ„í•œ ì¸ì‚¬ì´íŠ¸

ì´ ë°ëª¨ë¥¼ í†µí•´ ì•Œ ìˆ˜ ìˆëŠ” ê²ƒ:

1. **ë°ì´í„°ê°€ ëª¨ë¸ì´ë‹¤**: 70,000ì¥ì˜ ë ˆì´ë¸”ëœ ë°ì´í„° ì—†ì´ëŠ” ë¶ˆê°€ëŠ¥
2. **ì •í™•ë„ 97%ì˜ ì˜ë¯¸**: 100ë²ˆ ì¤‘ 3ë²ˆ í‹€ë¦¼ â†’ ì˜ë£Œ/ê¸ˆìœµ ì„œë¹„ìŠ¤ì—ì„  ì¹˜ëª…ì ì¼ ìˆ˜ ìˆìŒ
3. **ì‹¤ì„œë¹„ìŠ¤ ì ìš© ì‹œ**: ì˜¤ë¶„ë¥˜ ì¼€ì´ìŠ¤ë¥¼ ì‚¬ëŒì´ ê²€ìˆ˜í•˜ëŠ” Human-in-the-Loop ì„¤ê³„ í•„ìš”
4. **í™•ì¥ ê°€ëŠ¥ì„±**: ê°™ì€ ì›ë¦¬ë¡œ ì†ê¸€ì”¨ ì˜ìˆ˜ì¦ ì¸ì‹, ì„œëª… ì¸ì¦, ë¬¸ì„œ ìŠ¤ìº” ë¶„ë¥˜ ê°€ëŠ¥

---

## ë§ˆë¬´ë¦¬: ì–¸ì œ ë¬´ì—‡ì„ ì¨ì•¼ í•˜ëŠ”ê°€?

### ê¸°ìˆ  ì„ íƒ ê°€ì´ë“œ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  AI ê¸°ìˆ  ì„ íƒ ì˜ì‚¬ê²°ì •                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ìƒí™©            â”‚ ì í•©í•œ ê¸°ìˆ                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ìˆ˜ì¹˜ë¥¼ ì˜ˆì¸¡     â”‚ íšŒê·€ (ê°€ê²©, ìˆ˜ìš”, ê¸°ì˜¨)                â”‚
â”‚ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜   â”‚ ë¶„ë¥˜ (ìŠ¤íŒ¸, ê°ì„±, ìœ í˜•)                â”‚
â”‚ ê·¸ë£¹ ìë™ ë°œê²¬  â”‚ êµ°ì§‘í™” (ê³ ê° ì„¸ê·¸ë¨¼íŠ¸)                 â”‚
â”‚ í…ìŠ¤íŠ¸ í•µì‹¬ íŒŒì•…â”‚ í‚¤ì›Œë“œ ë¶„ì„ (ë¦¬ë·°, VOC)               â”‚
â”‚ ê°œë… ê´€ê³„ êµ¬ì¡°  â”‚ í‚¤ì›Œë“œ ë„¤íŠ¸ì›Œí¬ (ë¸Œëœë“œ, íŠ¸ë Œë“œ í—ˆë¸Œ)  â”‚
â”‚ ìˆ¨ì€ ì£¼ì œ ë°œê²¬  â”‚ í† í”½ ë¶„ì„/LDA (ë‰´ìŠ¤, ë¦¬ë·° í† í”½ ì¶”ì¶œ)  â”‚
â”‚ ëŒ€í™”/ì§ˆì˜ì‘ë‹µ   â”‚ LLM (ChatGPT, Claude)                 â”‚
â”‚ ì´ë¯¸ì§€ ìƒì„±     â”‚ ì´ë¯¸ì§€ ìƒì„± AI (Midjourney, DALL-E)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ê³ ì „ì  AI vs LLM ë¹„êµ

| í•­ëª© | ê³ ì „ì  ML/NLP | LLM (GPT, Claude ë“±) |
|------|---------------|----------------------|
| ì²˜ë¦¬ ì†ë„ | ë§¤ìš° ë¹ ë¦„ | ìƒëŒ€ì ìœ¼ë¡œ ëŠë¦¼ |
| ë¹„ìš© | ì €ë ´ | í† í°ë‹¹ ë¹„ìš© ë°œìƒ |
| ì •í™•ë„ | íŠ¹ì • íƒœìŠ¤í¬ íŠ¹í™” ì‹œ ë†’ìŒ | ë²”ìš©, ìœ ì—° |
| ì„¤ëª… ê°€ëŠ¥ì„± | ë†’ìŒ | ë‚®ìŒ (ë¸”ë™ë°•ìŠ¤) |
| ë°ì´í„° í•„ìš”ëŸ‰ | ìˆ˜ì²œ~ìˆ˜ë§Œ ê±´ | ê±°ì˜ ë¶ˆí•„ìš” (Few-shot) |
| ìœ ì§€ë³´ìˆ˜ | ì¬í•™ìŠµ í•„ìš” | í”„ë¡¬í”„íŠ¸ ìˆ˜ì •ìœ¼ë¡œ ëŒ€ì‘ |
| ì í•©í•œ íƒœìŠ¤í¬ | ë°˜ë³µì , ëŒ€ìš©ëŸ‰, ì˜ˆì¸¡ | ì°½ì˜ì , ë³µì¡í•œ ì´í•´ |

### ì˜¤ëŠ˜ì˜ í•µì‹¬ ë©”ì‹œì§€ 3ê°€ì§€

> **1ï¸âƒ£ AI ì„œë¹„ìŠ¤ = LLMì´ ì•„ë‹™ë‹ˆë‹¤**  
> ì—¬ëŸ¬ë¶„ ì£¼ë³€ ëŒ€ë¶€ë¶„ì˜ AI ì„œë¹„ìŠ¤ëŠ” ê³ ì „ì  MLê³¼ NLPë¡œ ìš´ì˜ ì¤‘ì…ë‹ˆë‹¤.

> **2ï¸âƒ£ ê¸°íšìÂ·ë””ìì´ë„ˆë„ ê¸°ìˆ ì„ ì´í•´í•´ì•¼ í•©ë‹ˆë‹¤**  
> êµ¬í˜„ ë°©ë²•ì€ ëª°ë¼ë„, "ì´ ê¸°ëŠ¥ì—” ë¶„ë¥˜ ëª¨ë¸ì´ í•„ìš”í•˜ê³ , í•™ìŠµ ë°ì´í„°ê°€ í•„ìš”í•˜ë‹¤"ëŠ” íŒë‹¨ì€ í•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

> **3ï¸âƒ£ ë°ì´í„°ê°€ AI ì„œë¹„ìŠ¤ì˜ í•µì‹¬ ìì‚°ì…ë‹ˆë‹¤**  
> ì–´ë–¤ ë°ì´í„°ë¥¼ ì–´ë–»ê²Œ ëª¨ì„ì§€ê°€ ê¸°íš ë‹¨ê³„ë¶€í„° ì„¤ê³„ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

---

## Part 4. ì‹¤ìŠµ ë°ëª¨ â€” MNIST ì›¹ ì•± (app.py)

> MNIST ë¶„ë¥˜ ëª¨ë¸ì„ Flask ì›¹ ì„œë²„ë¡œ ê°ì‹¸, ë¸Œë¼ìš°ì €ì—ì„œ ì§ì ‘ ìˆ«ìë¥¼ ê·¸ë¦¬ê³  ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í™•ì¸í•˜ëŠ” ì¸í„°ë™í‹°ë¸Œ ë°ëª¨ì…ë‹ˆë‹¤.

### ì‹¤í–‰ ë°©ë²•

```bash
uv run python script/app.py
# ë¸Œë¼ìš°ì €ì—ì„œ http://127.0.0.1:8080 ì ‘ì†
```

ìµœì´ˆ ì‹¤í–‰ ì‹œ MNIST í•™ìŠµ í›„ `model/mnist_rf.pkl`ë¡œ ì €ì¥í•˜ê³ , ì´í›„ ì‹¤í–‰ë¶€í„°ëŠ” ì €ì¥ëœ ëª¨ë¸ì„ ì¦‰ì‹œ ë¡œë“œí•©ë‹ˆë‹¤.

### ë™ì‘ êµ¬ì¡°

```mermaid
flowchart TD
    A["ì•± ì‹œì‘"] --> B{"model/mnist_rf.pkl ì¡´ì¬?"}
    B -- "ì¡´ì¬" --> C["ëª¨ë¸ ì¦‰ì‹œ ë¡œë“œ"]
    B -- "ì—†ìŒ" --> D["MNIST í•™ìŠµ í›„ ì €ì¥ (ìµœì´ˆ 1íšŒ)"]
    C --> E["ë¸Œë¼ìš°ì €: ìº”ë²„ìŠ¤ì— ìˆ«ì ê·¸ë¦¬ê¸°\n(ê²€ì • ë°°ê²½ + í° ì„ )"]
    D --> E
    E --> F["[ì˜ˆì¸¡] ë²„íŠ¼ â†’ base64 PNGë¥¼ /predictë¡œ ì „ì†¡"]
    F --> G["ì„œë²„: 28Ã—28 ë¦¬ì‚¬ì´ì¦ˆ â†’ ì •ê·œí™” â†’ ëª¨ë¸ ì¶”ë¡ "]
    G --> H["ì˜ˆì¸¡ ìˆ«ì + 0~9 í™•ë¥  ë§‰ëŒ€ í‘œì‹œ (ìµœê³  í™•ë¥  í•­ëª© ê°•ì¡°)"]
```

### í•µì‹¬ ì½”ë“œ

```python
# pip install flask pillow scikit-learn

import base64, io, joblib, numpy as np
from PIL import Image
from flask import Flask, request, jsonify, render_template_string
from sklearn.datasets import fetch_openml
from sklearn.ensemble import RandomForestClassifier

MODEL_PATH = 'model/mnist_rf.pkl'
app = Flask(__name__)
model = None

def load_or_train():
    global model
    if os.path.exists(MODEL_PATH):
        model = joblib.load(MODEL_PATH)          # ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ
    else:
        mnist = fetch_openml('mnist_784', version=1, as_frame=False)
        X, y = mnist.data / 255.0, mnist.target
        model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
        model.fit(X[:60000], y[:60000])
        joblib.dump(model, MODEL_PATH)           # ëª¨ë¸ ì €ì¥

@app.route('/predict', methods=['POST'])
def predict():
    # ìº”ë²„ìŠ¤ ì´ë¯¸ì§€(base64 PNG) â†’ 28Ã—28 ë°°ì—´ â†’ ëª¨ë¸ ì¶”ë¡ 
    img_bytes = base64.b64decode(request.json['image'].split(',')[1])
    img = Image.open(io.BytesIO(img_bytes)).convert('L').resize((28, 28))
    arr = np.array(img, dtype=np.float32).reshape(1, -1) / 255.0

    pred  = model.predict(arr)[0]
    proba = model.predict_proba(arr)[0]
    return jsonify({
        'prediction': pred,
        'probabilities': [{'digit': c, 'prob': float(p)}
                          for c, p in zip(model.classes_, proba)]
    })

if __name__ == '__main__':
    load_or_train()
    app.run(host='0.0.0.0', port=8080)
```

### ê¸°íšìÂ·ë””ìì´ë„ˆê°€ ì•Œì•„ì•¼ í•  í¬ì¸íŠ¸

- **ëª¨ë¸ ì €ì¥(Persistence)**: í•™ìŠµëœ ëª¨ë¸ì„ íŒŒì¼ë¡œ ì €ì¥í•´ ë‘ë©´ ì„œë¹„ìŠ¤ ì¬ì‹œì‘ ì‹œì—ë„ ì¬í•™ìŠµ ì—†ì´ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥ â€” ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œ í•„ìˆ˜ íŒ¨í„´
- **ì…ë ¥ ì „ì²˜ë¦¬ì˜ ì¤‘ìš”ì„±**: ìº”ë²„ìŠ¤ëŠ” 280Ã—280ì´ì§€ë§Œ MNISTëŠ” 28Ã—28 â€” ë¦¬ì‚¬ì´ì¦ˆÂ·ì •ê·œí™” ì—†ì´ëŠ” ì •í™•ë„ê°€ í¬ê²Œ ë–¨ì–´ì§
- **í™•ë¥  ì œê³µ**: ë‹¨ìˆœ "ì˜ˆì¸¡ê°’" ëŒ€ì‹  0~9 ê°ê°ì˜ í™•ë¥ ì„ ì œê³µí•˜ë©´ UXì—ì„œ ì‹ ë¢°ë„ í‘œì‹œì— í™œìš© ê°€ëŠ¥

---

## ğŸ“š ë” ì•Œì•„ë³´ê¸°

**ë¬´ë£Œ ì‹¤ìŠµ í™˜ê²½**

- [Google Colab](https://colab.research.google.com) â€” ë¸Œë¼ìš°ì €ì—ì„œ ë°”ë¡œ Python ì‹¤í–‰
- [Kaggle](https://www.kaggle.com) â€” ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ê³¼ íŠœí† ë¦¬ì–¼

**ì¶”ì²œ í•™ìŠµ ìë£Œ**

- scikit-learn ê³µì‹ ë¬¸ì„œ: <https://scikit-learn.org>
- KoNLPy í•œêµ­ì–´ NLP: <https://konlpy.org>
- êµ¬ê¸€ ë¨¸ì‹ ëŸ¬ë‹ ì…ë¬¸ ê°•ì¢Œ: <https://developers.google.com/machine-learning/crash-course>
